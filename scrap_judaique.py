# -*- coding: utf-8 -*-
"""Scrap_Judaique

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cPvnKc0SoiIPpvEmZhHht35G2AJXJO0k
"""

import requests
import pandas as pd
from datetime import datetime

# URL de l'API (on garde la m√™me base)
BASE_URL = "https://datahub.bordeaux-metropole.fr/api/records/1.0/search/"

params = {
    "dataset": "bor_frequentation_piscine_tr",
    "rows": 50,  # On r√©cup√®re tout pour filtrer nous-m√™me
    "q": ""
}

def afficher_affluence_judaique():
    print("üîÑ R√©cup√©ration des donn√©es corrig√©es...")

    try:
        response = requests.get(BASE_URL, params=params)
        data = response.json()

        if data['nhits'] > 0:
            # On r√©cup√®re les champs des r√©sultats
            records = [r['fields'] for r in data['records']]
            df = pd.DataFrame(records)

            # --- FILTRAGE POUR JUDA√èQUE ---
            # On cherche "Juda" ou "Boiteux" dans la colonne 'etablissement_etalib'
            # (Note: par s√©curit√©, on convertit en cha√Æne de caract√®res 'str')
            resultat = df[df['etablissement_etalib'].astype(str).str.contains("Juda|Boiteux", case=False, na=False)]

            if not resultat.empty:
                # On prend la premi√®re ligne trouv√©e (souvent le grand bassin)
                # Il est possible qu'il y ait plusieurs zones (bassin 25m, 50m, etc.)
                # On va faire une boucle pour tout afficher si plusieurs zones existent

                print("\nüèä R√âSULTATS POUR PISCINE JUDA√èQUE - JEAN BOITEUX :")

                for index, row in resultat.iterrows():
                    zone = row.get('fmizonlib', 'Zone inconnue') # Nom de la zone (ex: Bassin 50m)
                    actuel = row.get('fmicourante', 0)           # Affluence actuelle
                    maximum = row.get('fmizonmax', 1)            # Capacit√© max
                    maj = row.get('datemiseajour', 'N/A')        # Heure de mise √† jour

                    # Calcul taux
                    try:
                        taux = round((actuel / maximum) * 100, 1)
                    except:
                        taux = 0

                    print("-" * 40)
                    print(f"üìç Zone : {zone}")
                    print(f"üë• Monde actuel : {actuel} personnes")
                    print(f"üìä Capacit√© max : {maximum} personnes")
                    print(f"üìà Remplissage  : {taux}%")
                    print(f"üïí Mis √† jour √† : {maj}")

                print("-" * 40)

            else:
                print("‚ùå Piscine Juda√Øque introuvable. Voici les piscines disponibles :")
                print(df['etablissement_etalib'].unique())
        else:
            print("‚ùå L'API ne renvoie aucune donn√©e pour le moment.")

    except Exception as e:
        print(f"‚ùå Erreur technique : {e}")

afficher_affluence_judaique()

"""V√©rification d'un historique des affluences."""

import requests
import pandas as pd

# On interroge le catalogue des datasets
CATALOG_URL = "https://datahub.bordeaux-metropole.fr/api/records/1.0/search/"
params = {
    "dataset": "met_donnees_dispo", # Catalogue des donn√©es disponibles
    "q": "piscine",
    "rows": 20
}

def chercher_archives():
    print("üïµÔ∏è Recherche de jeux de donn√©es d'archives...")
    try:
        # On fait une recherche globale sur le portail (pas sur un dataset pr√©cis)
        # Note: L'API catalogue sp√©cifique peut varier, on va utiliser une m√©thode plus simple :
        # On liste les datasets via l'API de recherche globale
        url_search = "https://datahub.bordeaux-metropole.fr/api/v2/catalog/datasets"
        params_search = {"q": "piscine", "rows": 20}

        response = requests.get(url_search, params=params_search)
        data = response.json()

        datasets_trouves = []
        if 'datasets' in data:
            for d in data['datasets']:
                info = d['dataset']
                datasets_trouves.append({
                    'ID Technique': info['dataset_id'],
                    'Titre': info['metas']['default']['title']
                })

            df = pd.DataFrame(datasets_trouves)
            pd.set_option('display.max_colwidth', None)
            display(df)
        else:
            print("Aucun dataset trouv√©.")

    except Exception as e:
        print(f"Erreur lors de la recherche : {e}")

chercher_archives()

"""Comme il n'y a pas d'historique on vient cr√©er le notre."""

import requests
import pandas as pd
import time
import os
from datetime import datetime
from google.colab import drive

# --- 1. CONFIGURATION ---
# On connecte le Google Drive pour stocker les donn√©es durablement
print("üìÇ Connexion √† Google Drive...")
drive.mount('/content/drive')

# Le fichier sera enregistr√© √† la racine de ton Drive
# Tu pourras le t√©l√©charger plus tard pour l'analyser
FICHIER_CSV = "/content/drive/MyDrive/historique_piscine_judaique.csv"

# L'URL du temps r√©el
BASE_URL = "https://datahub.bordeaux-metropole.fr/api/records/1.0/search/"
PARAMS = {
    "dataset": "bor_frequentation_piscine_tr",
    "rows": 20,
    "q": ""
}

# --- 2. FONCTION DE R√âCUP√âRATION ---
def enregistrer_donnees():
    try:
        response = requests.get(BASE_URL, params=PARAMS)
        data = response.json()

        timestamp = datetime.now()

        if data.get('nhits', 0) > 0:
            records = [r['fields'] for r in data['records']]
            df = pd.DataFrame(records)

            # On filtre uniquement sur Juda√Øque / Jean Boiteux
            # On convertit en string pour √©viter les erreurs si la colonne est vide
            mask = df['etablissement_etalib'].astype(str).str.contains("Juda|Boiteux", case=False, na=False)
            resultat = df[mask]

            lignes_a_sauver = []

            for idx, row in resultat.iterrows():
                # On structure la donn√©e proprement pour le Machine Learning plus tard
                ligne = {
                    "date_heure": timestamp,
                    "jour_semaine": timestamp.strftime("%A"), # Lundi, Mardi...
                    "heure": timestamp.hour,
                    "minute": timestamp.minute,
                    "piscine": row.get('etablissement_etalib'),
                    "zone": row.get('fmizonlib'),
                    "frequentation": row.get('fmicourante'),
                    "capacite": row.get('fmizonmax'),
                    "taux_remplissage": 0 # On calculera √ßa juste apr√®s
                }

                # Petit calcul de s√©curit√©
                if ligne["capacite"] and ligne["capacite"] > 0:
                    ligne["taux_remplissage"] = round(ligne["frequentation"] / ligne["capacite"] * 100, 2)

                lignes_a_sauver.append(ligne)

            # --- 3. SAUVEGARDE DANS LE CSV ---
            if lignes_a_sauver:
                df_new = pd.DataFrame(lignes_a_sauver)

                # Si le fichier existe, on ajoute √† la suite (mode 'a' ppend)
                if os.path.exists(FICHIER_CSV):
                    df_new.to_csv(FICHIER_CSV, mode='a', header=False, index=False)
                    print(f"‚úÖ {timestamp.strftime('%H:%M')} : Donn√©e ajout√©e (Total actuel : {row.get('fmicourante')} nageurs)")
                else:
                    # Sinon on le cr√©e (mode 'w' rite)
                    df_new.to_csv(FICHIER_CSV, mode='w', header=True, index=False)
                    print(f"üÜï {timestamp.strftime('%H:%M')} : Fichier cr√©√© avec succ√®s !")
            else:
                print(f"‚ö†Ô∏è {timestamp.strftime('%H:%M')} : Piscine Juda√Øque non trouv√©e dans le flux.")

        else:
            print("‚ùå Erreur API : Pas de donn√©es renvoy√©es.")

    except Exception as e:
        print(f"‚ùå Erreur critique : {e}")

# --- 4. LA BOUCLE INFINIE ---
print(f"üöÄ Le collecteur est lanc√© ! Fichier cible : {FICHIER_CSV}")
print("Ne ferme pas cet onglet tant que tu veux r√©colter des donn√©es.")
print("-" * 50)

try:
    while True:
        enregistrer_donnees()
        # Pause de 15 minutes (15 * 60 secondes)
        time.sleep(900)
except KeyboardInterrupt:
    print("\nüõë Collecte arr√™t√©e par l'utilisateur.")